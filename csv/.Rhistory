state <- sample(states$active,1)
} else{
state <- sample(states$sluggish,1)
}
if(weekend && rnorm(1,50,20) <= 10){
state <- 5 #nap on weekend
}
} else{
if((i>morningSkew && i<=(33+noise)) || i >= (138+skew)){
state <- sample(states$sleep,1)
} else if(i <= (36)){
state <- sample(states$sluggish,1)
} else if(i >= (132+skew)){
state <- sample(states$sluggish,1)
} else{
state <- sample(states$active,1)
}
} #end outer else-block
val <- mean(c(state,previous),na.rm=TRUE) + rnorm(1)
previous <<- val
morningSkew <<- morning
return(data.frame(day=daynum,div=i,activity=val))
}
L <- lapply(0:((numdays*numticks)-1),makeRow)
LL <- do.call(rbind,L)
library(ggplot2)
ggplot(LL) + geom_tile(aes(x=div,y=day,fill=activity))
#generate some random data
numdays <- 365
numticks <- 144
activityMax <- 100
states <- list(active=rnorm(1000,85,6), calm=rnorm(1000,69,14), sluggish=rnorm(1000,33,14), sleep=rnorm(1000,15,6))
previous <- NA
morningSkew <- 0
makeRow <- function(ticknum){
i <- ticknum%%144
daynum <- (ticknum-i)/144 #uses zero-indexing
if(daynum>=300){baby<-TRUE} else{baby<-FALSE}
if((daynum%%7 == 2 || daynum%%7 ==3)){weekend <- TRUE} else{weekend <- FALSE}
noise <- rnorm(1,0,2)
if(weekend && !baby){
skew <- sample(c(6,9,12),1,prob=c(0.25,0.5,0.25))+noise
morning <- skew
} else{
skew <- 0+noise
morning <- 0
}
if(baby){
if(i <= (6+skew)){
state <- sample(states$sleep,1)
} else if(i <= (12+skew) || i >= (92+skew)){
state <- sample(states$active,1)
} else if(i <= (24+skew)){
state <- sample(states$sleep,1)
} else if(i <= (30+skew)){
state <- sample(states$active,1)
} else if(i <= (36+skew)){
state <- sample(states$sluggish,1)
} else if(i <= (132+skew)){
state <- sample(states$active,1)
} else{
state <- sample(states$sluggish,1)
}
if(weekend && rnorm(1,50,20) <= 10){
state <- 5 #nap on weekend
}
} else{
if((i>morningSkew && i<=(33+noise+morningSkew)) || i >= (138+skew)){
state <- sample(states$sleep,1)
} else if(i <= (36+morningSkew)){
state <- sample(states$sluggish,1)
} else if(i >= (132+skew)){
state <- sample(states$sluggish,1)
} else{
state <- sample(states$active,1)
}
} #end outer else-block
val <- mean(c(state,previous),na.rm=TRUE) + rnorm(1)
previous <<- val
morningSkew <<- morning
return(data.frame(day=daynum,div=i,activity=val))
}
L <- lapply(0:((numdays*numticks)-1),makeRow)
LL <- do.call(rbind,L)
library(ggplot2)
ggplot(LL) + geom_tile(aes(x=div,y=day,fill=activity))
numdays <- 12
numticks <- 144
activityMax <- 100
states <- list(active=rnorm(1000,85,6), calm=rnorm(1000,69,14), sluggish=rnorm(1000,33,14), sleep=rnorm(1000,15,6))
previous <- NA
morningSkew <- 0
makeRow <- function(ticknum){
i <- ticknum%%144
daynum <- (ticknum-i)/144 #uses zero-indexing
if(daynum>=300){baby<-TRUE} else{baby<-FALSE}
if((daynum%%7 == 2 || daynum%%7 ==3)){weekend <- TRUE} else{weekend <- FALSE}
noise <- rnorm(1,0,2)
if(weekend && !baby){
skew <- sample(c(6,9,12),1,prob=c(0.25,0.5,0.25))+noise
morning <- skew
} else{
skew <- 0+noise
morning <- 0
}
if(baby){
if(i <= (6+skew)){
state <- sample(states$sleep,1)
} else if(i <= (12+skew) || i >= (92+skew)){
state <- sample(states$active,1)
} else if(i <= (24+skew)){
state <- sample(states$sleep,1)
} else if(i <= (30+skew)){
state <- sample(states$active,1)
} else if(i <= (36+skew)){
state <- sample(states$sluggish,1)
} else if(i <= (132+skew)){
state <- sample(states$active,1)
} else{
state <- sample(states$sluggish,1)
}
if(weekend && rnorm(1,50,20) <= 10){
state <- 5 #nap on weekend
}
} else{
if((i>morningSkew && i<=(33+noise+morningSkew)) || i >= (138+skew)){
state <- sample(states$sleep,1)
} else if(i <= (36+morningSkew)){
state <- sample(states$sluggish,1)
} else if(i >= (132+skew)){
state <- sample(states$sluggish,1)
} else{
state <- sample(states$active,1)
}
} #end outer else-block
val <- mean(c(state,previous),na.rm=TRUE) + rnorm(1)
previous <<- val
morningSkew <<- morning
return(data.frame(day=daynum,div=i,activity=val))
}
L <- lapply(0:((numdays*numticks)-1),makeRow)
LL <- do.call(rbind,L)
library(ggplot2)
ggplot(LL) + geom_tile(aes(x=div,y=day,fill=activity))
#generate some random data
numdays <- 12
numticks <- 144
activityMax <- 100
states <- list(active=rnorm(1000,85,6), calm=rnorm(1000,69,14), sluggish=rnorm(1000,33,14), sleep=rnorm(1000,15,6))
previous <- NA
morningSkew <- 0
makeRow <- function(ticknum){
i <- ticknum%%144
daynum <- (ticknum-i)/144 #uses zero-indexing
if(daynum>=300){baby<-TRUE} else{baby<-FALSE}
if((daynum%%7 == 2 || daynum%%7 ==3)){weekend <- TRUE} else{weekend <- FALSE}
noise <- rnorm(1,0,2)
if(weekend && !baby){
skew <- sample(c(6,9,12),1,prob=c(0.25,0.5,0.25))+noise
morning <- skew
} else{
skew <- 0+noise
morning <- 0
}
if(baby){
if(i <= (6+skew)){
state <- sample(states$sleep,1)
} else if(i <= (12+skew) || i >= (92+skew)){
state <- sample(states$active,1)
} else if(i <= (24+skew)){
state <- sample(states$sleep,1)
} else if(i <= (30+skew)){
state <- sample(states$active,1)
} else if(i <= (36+skew)){
state <- sample(states$sluggish,1)
} else if(i <= (132+skew)){
state <- sample(states$active,1)
} else{
state <- sample(states$sluggish,1)
}
if(weekend && rnorm(1,50,20) <= 10){
state <- 5 #nap on weekend
}
} else{
if((i>morningSkew && i<=(33+noise+morningSkew)) || i >= (138+skew)){
state <- sample(states$sleep,1)
} else if(i <= (36+morningSkew)){
state <- sample(states$sluggish,1)
} else if(i >= (132+skew)){
state <- sample(states$sluggish,1)
} else{
state <- sample(states$active,1)
}
} #end outer else-block
val <- mean(c(state,previous),na.rm=TRUE) + rnorm(1)
print(morningSkew)
previous <<- val
morningSkew <<- morning
return(data.frame(day=daynum,div=i,activity=val))
}
L <- lapply(0:((numdays*numticks)-1),makeRow)
LL <- do.call(rbind,L)
library(ggplot2)
ggplot(LL) + geom_tile(aes(x=div,y=day,fill=activity))
q()
library(reshape2)
raw <- read.csv("/home/alec/Dropbox/Projects/Brookings/DataViz/DiversityExplosion/data/source/CC-EST2013-ALLDATA.csv")
raw[raw$YEAR==6,]
raw <- raw[raw$YEAR==6,]
raw <- read.csv("/home/alec/Dropbox/Projects/Brookings/DataViz/DiversityExplosion/data/source/CC-EST2013-ALLDATA.csv")
raw <- raw[raw$YEAR==6,]
vars <- c("TOT_POP", "TOT_MALE", "TOT_FEMALE", "WA_MALE", "WA_FEMALE",
"BA_MALE", "BA_FEMALE", "IA_MALE", "IA_FEMALE", "AA_MALE", "AA_FEMALE",
"NA_MALE", "NA_FEMALE", "TOM_MALE", "TOM_FEMALE", "WAC_MALE",
"WAC_FEMALE", "BAC_MALE", "BAC_FEMALE", "IAC_MALE", "IAC_FEMALE",
"AAC_MALE", "AAC_FEMALE", "NAC_MALE", "NAC_FEMALE", "NH_MALE",
"NH_FEMALE", "NHWA_MALE", "NHWA_FEMALE", "NHBA_MALE", "NHBA_FEMALE",
"NHIA_MALE", "NHIA_FEMALE", "NHAA_MALE", "NHAA_FEMALE", "NHNA_MALE",
"NHNA_FEMALE", "NHTOM_MALE", "NHTOM_FEMALE", "NHWAC_MALE", "NHWAC_FEMALE",
"NHBAC_MALE", "NHBAC_FEMALE", "NHIAC_MALE", "NHIAC_FEMALE", "NHAAC_MALE",
"NHAAC_FEMALE", "NHNAC_MALE", "NHNAC_FEMALE", "H_MALE", "H_FEMALE",
"HWA_MALE", "HWA_FEMALE", "HBA_MALE", "HBA_FEMALE", "HIA_MALE",
"HIA_FEMALE", "HAA_MALE", "HAA_FEMALE", "HNA_MALE", "HNA_FEMALE",
"HTOM_MALE", "HTOM_FEMALE", "HWAC_MALE", "HWAC_FEMALE", "HBAC_MALE",
"HBAC_FEMALE", "HIAC_MALE", "HIAC_FEMALE", "HAAC_MALE", "HAAC_FEMALE",
"HNAC_MALE", "HNAC_FEMALE")
melted <- melt(raw,id.vars=c("SUMLEV","STATE","COUNTY","STNAME","CTYNAME","YEAR","AGEGRP"), measure.vars=vars, variable.name="Group", value.name="Pop")
collapseSex <- c("TOT_POP", "TOT", "TOT", "WA", "WA",
"BA", "BA", "IA", "IA", "AA", "AA",
"NA", "NA", "TOM", "TOM", "WAC",
"WAC", "BAC", "BAC", "IAC", "IAC",
"AAC", "AAC", "NAC", "NAC", "NH",
"NH", "NHWA", "NHWA", "NHBA", "NHBA",
"NHIA", "NHIA", "NHAA", "NHAA", "NHNA",
"NHNA", "NHTOM", "NHTOM", "NHWAC", "NHWAC",
"NHBAC", "NHBAC", "NHIAC", "NHIAC", "NHAAC",
"NHAAC", "NHNAC", "NHNAC", "H", "H",
"HWA", "HWA", "HBA", "HBA", "HIA",
"HIA", "HAA", "HAA", "HNA", "HNA",
"HTOM", "HTOM", "HWAC", "HWAC", "HBAC",
"HBAC", "HIAC", "HIAC", "HAAC", "HAAC",
"HNAC", "HNAC")
collapseSex <- data.frame(Group=vars,Group2=collapseSex)
Ages <- c("Total",
"Age 0 to 4 years",
"Age 5 to 9 years",
"Age 10 to 14 years",
"Age 15 to 19 years",
"Age 20 to 24 years",
"Age 25 to 29 years",
"Age 30 to 34 years",
"Age 35 to 39 years",
"Age 40 to 44 years",
"Age 45 to 49 years",
"Age 50 to 54 years",
"Age 55 to 59 years",
"Age 60 to 64 years",
"Age 65 to 69 years",
"Age 70 to 74 years",
"Age 75 to 79 years",
"Age 80 to 84 years",
"Age 85 years or older")
Ages2 <- c("Total",
"0to4",
"5to19",
"5to19",
"5to19",
"20to34",
"20to34",
"20to34",
"35to49",
"35to49",
"35to49",
"50to64",
"50to64",
"50to64",
"65to79",
"65to79",
"65to79",
"80plus",
"80plus")
collapseAge <- data.frame(AGEGRP=0:18,Age=Ages,Age2=Ages2)
melted <- merge(melted,collapseSex,by="Group")
nrow(melted)
melted <- merge(melted,collapseAge,by="AGEGRP")
nrow(melted)
sums <- aggregate(melted["Pop"],by=melted[c("SUMLEV","STATE","COUNTY","STNAME","CTYNAME","YEAR","Group2","Age2")],sum)
View(sums)
casted <- dcast(sums, SUMLEV+STATE+COUNTY+STNAME+CTYNAME+YEAR~Group2+Age2, value.var="Pop")
View(casted)
names(casted)
View(sums)
sums$stcofips <- ifelse(sums$STATE<10,paste("0",sums$STATE,sep=""),sums$STATE)
View(sums)
sums$stcofips <- paste(sums$stcofips, ifelse(sums$COUNTY<10,paste("00",sums$COUNTY,sep=""),ifelse(sums$COUNTY<100,paste("0",sums$COUNTY,sep=""),as.character(sums$COUNTY))),sep="")    )
sums$stcofips <- ifelse(sums$STATE<10,paste("0",sums$STATE,sep=""),sums$STATE)
sums$stcofips <- paste(sums$stcofips, ifelse(sums$COUNTY<10,paste("00",sums$COUNTY,sep=""),ifelse(sums$COUNTY<100,paste("0",sums$COUNTY,sep=""),as.character(sums$COUNTY))),sep="")
View(sums)
cSplit <- split(sums,sums$stcofips)
sums$stcofips <- ifelse(sums$STATE<10,paste("0",sums$STATE,sep=""),sums$STATE)
sums$stcofips <- paste("C",sums$stcofips, ifelse(sums$COUNTY<10,paste("00",sums$COUNTY,sep=""),ifelse(sums$COUNTY<100,paste("0",sums$COUNTY,sep=""),as.character(sums$COUNTY))),sep="")
cSplit <- split(sums,sums$stcofips)
cSplit <- split(sums,sums$stcofips)
cSplit2 <- lapply(cSplit[1:3],function(e){
e <- e[,c("stcofips","Group2","Age2","Pop")]
eSplit <- split(e,e$Group2)
ret <- lapply(eSplit,function(e){
return(split(e,e$Age2))
})
return(ret)
})
cSplit2[[1]]
str(cSplit2)
cSplit2 <- lapply(cSplit[1],function(e){
e <- e[,c("stcofips","Group2","Age2","Pop")]
eSplit <- split(e,e$Group2)
ret <- lapply(eSplit,function(e){
return(split(e,e$Age2))
})
return(ret)
})
str(cSplit2)
cSplit2 <- lapply(cSplit,function(e){
e <- e[,c("stcofips","Group2","Age2","Pop")]
eSplit <- split(e,e$Group2)
ret <- lapply(eSplit,function(e){
return(split(e,e$Age2))
})
return(ret)
})
library(jsonlite)
toJSON(cSplit2[1])
json <- toJSON(cSplit2,na="null")
cSplit2 <- lapply(cSplit,function(e){
e <- e[,c("Group2","Age2","Pop")]
eSplit <- split(e,e$Group2)
ret <- lapply(eSplit,function(e){
eSplit <- split(e[c("Age2","Pop")],e$Age2)
return(lapply(eSplit,function(e){
return(e$Pop)
}))
})
return(ret)
})
json <- toJSON(cSplit2,na="null")
writeLines(json,"/home/alec/Dropbox/Projects/Brookings/DataViz/DiversityExplosion/data/json/countydat.json")
save(sums, file="/home/alec/Dropbox/Projects/Brookings/DataViz/DiversityExplosion/data/json/RDat.RData")
q()
source("/home/alec/Dropbox/Projects/Brookings/DataViz/FreightFlows/R/1. Import and Process.R")
library(ggplot2)
flowList <- split(flows,flows$Group_ID)
#big function to be applied to each member of flowList
squareMatrix <- function(df){
#Commodity code
commCode <- df[1,"Group_ID"]
print(paste("Running data for commodity group",commCode))
#Largest Domestic
sumDomestic <- aggregate(df["Value_2010"],df["Metro_Code"],sum)
sumDomestic <- merge(lookupD,sumDomestic,by.x="Geo_ID",by.y="Metro_Code")
sumDomestic <- sumDomestic[order(sumDomestic$Value_2010,decreasing=TRUE),]
#Largest Foreign
sumForeign <- aggregate(df["Value_2010"],df["Trader_Code"],sum)
sumForeign <- merge(lookupG,sumForeign,by.x="Geo_ID",by.y="Trader_Code")
sumForeign <- sumForeign[order(sumForeign$Value_2010,decreasing=TRUE),]
numDom <- nrow(sumDomestic)
numFor <- nrow(sumForeign)
if(numDom > 75){numDom <- 75}
if(numFor > 25){numFor <- 25}
print(paste("Pulling the top",numDom,"domestic flows and the top",numFor,"foreign flows"))
if(numDom > 0 && numFor > 0){
sums <- rbind(sumDomestic[1:numDom,],sumForeign[1:numFor,]) #top 75 domestic, top 25 foreign
} else if(numDom > 0){
sums <- sumDomestic[1:numDom,]
} else if(numFor > 0){
sums <- sumForeign[1:numFor,]
}
sums <- sums[order(sums$Viz_Tick),]
GC4Matrix <- as.character(sumForeign[1:25,"Geo_ID"])
GlobalCodeStacker <- data.frame(Trader_Code=GC4Matrix,Value_2010=0) #used as a spacer below to round out square matrix
makeRow <- function(e){
e <- as.character(e) #convert to character
#extract data for this code
if(e %in% as.character(lookupD$Geo_ID)){
dat <- df[as.character(df$Metro_Code)==e,c("Metro_Code","Trader_Code","Value_2010")]
dat <- rbind(dat,data.frame(Metro_Code=e,Trader_Code=e,Value_2010=0)) #to complete square matrix
names(dat) <- c("Metro1","Metro2","Value")
} else if(e %in% as.character(lookupG$Geo_ID)){
dat <- df[as.character(df$Trader_Code)==e,c("Trader_Code","Metro_Code","Value_2010")]
GlobalCodeStacker$Metro_Code <- e #since this actually reassigns to GlobalCodeStacker, and assignments are done in local scope (<- vs <<-), it does not affect the outer value (i.e. a local copy is made)
dat <- rbind(dat,GlobalCodeStacker)
names(dat) <- c("Metro1","Metro2","Value")
} else{
print(paste("No data found for:",e))
dat <- data.frame(Metro1=character(0),Metro2=character(0),Value=numeric(0));
}
#need to limit the number of connections to the chosen universe of top 75/25 (matrix must be square)
dat <- dat[as.character(dat$Metro2) %in% as.character(sums$Geo_ID),]
if(nrow(dat) < nrow(sums)){
#if there are missing connections listed, pad the data with 0s
nodata <- sums[!(sums$Geo_ID %in% dat$Metro2),"Geo_ID"]
nodata <- data.frame(Metro2=nodata)
nodata$Metro1 <- e
nodata$Value <- 0
dat <- rbind(dat,nodata)
}
dat[dat$Value < 0.1,"Value"] <- 0 #prevents errors in D3 rendering
#reorder dat so it matches the order of Viz_Tick
if(!is.null(dat)){
dat$order <- factor(dat$Metro2,levels=as.character(sums$Geo_ID)) #row will be sorted in same order as sums
dat <- dat[order(dat$order),]
row <- matrix(dat$Value,nrow=1,dimnames=list(Metro1=e,Metro2=as.character(dat$Metro2)))
}
return(row)
} #end makeRow
getMax <- function(e){
e <- as.character(e) #convert to character
#extract data for this code
if(e %in% as.character(lookupD$Geo_ID)){
dat <- df[as.character(df$Metro_Code)==e,"Value_2010"]
} else if(e %in% as.character(lookupG$Geo_ID)){
dat <- df[as.character(df$Trader_Code)==e,"Value_2010"]
} else{
print(paste("No data found for:",e))
dat <- NULL
}
return(max(dat))
}
allRows <- lapply(sums$Geo_ID,makeRow) #relies on sums being sorted
bigMatrix <- do.call(rbind,allRows)
labels <- sums[c("fullname","CensusDiv","Geo_ID")]
maxVals <- sapply(sums$Geo_ID,getMax)
return(list(data=bigMatrix,places=labels,max=maxVals,commodity=commCode))
}
options(scipen=999)
bigBigMatrix <- lapply(flowList,squareMatrix)
bigBigMatris[[1]]
bigBigMatrix[[1]]
length(bigBigMatrix)
library(jsonlite)
for(i in 1:length(bigBigMatrix)){
writeLines(toJSON(bigBigMatrix[[i]]),paste("/home/alec/Dropbox/Projects/Brookings/DataViz/FreightFlows/json_final/chord_data/bigMatrix_",bigBigMatrix[[i]]$commodity,".json",sep=""))
}
sumByComm <- aggregate(flows["Value_2010"],flows[c("Metro_Code","Group_ID")],"sum")
maxByComm <- aggregate(sumByComm["Value_2010"],sumByComm["Group_ID"],"max")
getFlow <- function(geoID,geoNM,num=50){
e <- as.character(geoID) #convert to character
#extract data for this (domestic) code
AllDat <- flows[as.character(flows$Metro_Code)==e,c("Metro_Code","Trader_Code","Value_2010","Group_ID")]
AllDat$Group_ID <- paste("comm",AllDat$Group_ID,sep="")
datList <- split(AllDat,AllDat$Group_ID)
groupOperator <- function(dat){
dat <- dat[order(dat$Value_2010,decreasing=TRUE),]
tot <- sum(dat$Value_2010)
comm <- as.numeric(sub("comm","",unique(dat$Group_ID)))
if(length(comm)==1){
if(comm==0){
commNm <- "All Commodities (Total Trade)"
} else{
commNm <- commlookup[commlookup$Group_ID==comm,"Commodity_Group"]
}
maxVal <- maxByComm[maxByComm$Group_ID==comm,"Value_2010"]
} else{
commNm <- ""
maxVal <- NA
warning("Problem detecting the commodity group name")
}
N <- nrow(dat)
if(N==0){warning("WARNING: No data for selected geography.")}
cum <- 0
names(dat) <- c("Metro1","Metro2","Value","GroupID")
whatShare <- function(e){
cum <<- e + cum
return(cum/tot)
}
shares <- sapply(dat$Value,whatShare)
if(num >= N){
warning(paste("You've selected",num, "flows.","The data contain",N,"flows."))
keepers <- dat
otherTotal <- 0
} else{
keepers <- dat[1:num,]
others <- dat[(num+1):N,]
otherTotal <- sum(others$Value)
print(paste("Rolling up",nrow(others),"observations into an 'other' category, accounting for",otherTotal,"dollars, or",round(otherTotal/tot,4),"of all value."))
}
#print(which(duplicated(keepers$Metro2)))
#keepers <- aggregate(keepers["Value"],by=keepers["Metro2"],sum) #why would you need this
#keepers <- keepers[order(keepers$Value,decreasing=TRUE),]
row_num_check <- nrow(keepers)
keepers <- merge(keepers,lookup2[c("Geo_ID","fullname","Viz_Tick","CensusDiv")],by.x="Metro2",by.y="Geo_ID")
if(row_num_check!=nrow(keepers)){stop("Bad lookup of geo names")}
keepers <- keepers[order(keepers$Value,decreasing=TRUE),c("fullname","Metro2","CensusDiv","Value")]
names(keepers) <- c("nm","id","div","val")
keepers <- rbind(keepers,data.frame(nm="All Other Trading Partners",id="OTHER",div="OTHER",val=otherTotal))
return(list(focusGeoName=geoNM,commNM=commNm,focusGeoVal=tot,allGeoMax=maxVal,flows=keepers))
}
RET <- lapply(datList,groupOperator)
return(RET)
}
library(jsonlite)
library(jsonlite)
for(i in 1:nrow(lookupD)){
writeLines(toJSON(getFlow(lookupD[i,"Geo_ID"],lookupD[i,"fullname"])),paste("/home/alec/Dropbox/Projects/Brookings/DataViz/FreightFlows/json_final/detailed_flows/",lookupD[i,"Geo_ID"],".json",sep=""))
}
View(commlookup)
str(commlookup)
index <- list(
places = lookupD[order(as.character(lookupD$fullname)),c("Geo_ID","fullname","CensusDiv")],
commodities = rbind(data.frame(Group_ID=0,Commodity_Group="All Commodities (Total Trade)"),commlookup[commlookup$Group_ID!=15,])
)
writeLines(toJSON(index),"/home/alec/Dropbox/Projects/Brookings/DataViz/FreightFlows/json_final/index.json")
q()
