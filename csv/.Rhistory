install.packages("ggplot2")
install.packages("sp")
install.packages("rgdal")
library(metrotools)
library rgdal
library(rgdal)
install.packages("rgdal")
install.packages("sp")
update.packages()
install.packages("lattice")
install.packages("sp")
install.packages("rgdal")
install.packages("ggplot2")
install.packages("digest")
install.packages("ggplot2")
install.packages("gtable")
install.packages("ggplot2")
install.packages("plyr")
install.packages("ggplot2")
install.packages("proto")
install.packages("ggplot2")
install.packages("reshape2")
install.packages("stringr")
install.packages("reshape2")
install.packages("ggplot2")
install.packages("scales")
install.packages("RColorBrewer")
install.packages("scales")
install.packages("munsell")
install.packages("scales")
install.packages("dichromat")
install.packages("scales")
install.packages("labeling")
install.packages("scales")
install.packages("codetools")
install.packages("scales")
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("devtools")
install.packages("RCurl")
install.packages("bitops")
install.packages("RCurl")
install.packages("devtools")
install.packages("evaluate")
install.packages("devtools")
install.packages("httr")
install.packages("devtools")
install.packages("memoise")
install.packages("devtools")
install.packages("whisker")
install.packages("devtools")
?install.packages
?update.packages
update.packages()
install.packages("roxygen")
install.packages("roxygen2")
remove.packages("roxygen")
install.packages(roxygen2)
install.packages("roxygen2")
install.packages("brew")
install.packages("roxygen2")
install.packages("RJSONIO")
plot(rnorm(20),rnorm(20))
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
q()
q()
library(metromonitor)
.libPaths()
a<-data.frame(a=1:10)
install.packages("maptools")
install.packages('ggmap')
setwd("/home/alec/Dropbox/Projects/Brookings/DataViz/FreightFlows/csv")
flows <- read.csv("DataViz_AllRoutes.txt",stringsAsFactors=TRUE,row.names=NULL)
lookup <- read.csv("DataViz_GeoLookup.txt",stringsAsFactors=TRUE,row.names=NULL)
lookup2 <- read.csv("LookupV2.csv",stringsAsFactors=TRUE,row.names=NULL)
lookup2 <- rbind(lookup2[81:450,],lookup2[1:80,])
lookup2$Viz_Tick <- 1:450
lookupD <- lookup2[lookup2$Geo_Type=="Domestic",]
lookupG <- lookup2[lookup2$Geo_Type=="Global" & lookup2$Geo_Description != "Unknown",]
load("geocodes5.RData")
#NOTE:
#Data contain duplicates when viewing total volume, e.g. Akron -> Atlanta and Atlanta -> Akron are in the data.
#However, the global geographies do not appear in the Metro_Code field so those pairs are not duplicated
#Example:
flows[with(flows,(Metro_Code==10180 & Trader_Code=="10420")|(Metro_Code==10420 & Trader_Code=="10180")),]
pairs <- paste(flows$Metro_Code,flows$Trader_Code,sep="-")
pairs2 <- sapply(pairs,function(el){
s <- strsplit(el,"-")
c <- sort(unlist(s))
return(paste(c,collapse="-"))
},USE.NAMES=FALSE)
flows$pair <- pairs2
##De-Duped flows
flowsDD <- flows[!duplicated(flows$pair),]
##De-Duped and Ordered flows
flowsDDO <- flowsDD[order(flowsDD$Value_2010,decreasing=TRUE),]
row.names(flowsDDO)<-NULL
flowsDDO$rank <- order(flowsDDO$Value_2010,decreasing=TRUE)
flowsDDO$FD <- ifelse(flowsDDO$Trader_Code %in% lookupD$Geo_ID,"Domestic","Global")
TOT <- sum(flowsDDO$Value_2010)
FD <- aggregate(flowsDDO["Value_2010"],by=flowsDDO["FD"],sum)
FD[1,"Value_2010"]/TOT #73.8% domestic
FD[2,"Value_2010"]/TOT #26.2% global
#ORDERING
#Largest Domestic
sumDomestic <- aggregate(flows[c("Value_2010","Outflow","Inflow")],flows["Metro_Code"],sum)
sumDomestic <- merge(lookupD,sumDomestic,by.x="Geo_ID",by.y="Metro_Code")
sumDomestic <- sumDomestic[order(sumDomestic$Value_2010,decreasing=TRUE),]
#Largest Foreign
sumForeign <- aggregate(flows[c("Value_2010","Outflow","Inflow")],flows["Trader_Code"],sum)
sumForeign <- merge(lookupG,sumForeign,by.x="Geo_ID",by.y="Trader_Code")
sumForeign <- sumForeign[order(sumForeign$Value_2010,decreasing=TRUE),]
#Code that, for a place, pulls 90% of traffic
getFlow <- function(geoID){
e <- as.character(geoID) #convert to character
#extract data for this (domestic) code
dat <- flows[as.character(flows$Metro_Code)==e,c("Metro_Code","Trader_Code","Value_2010","pair")]
dat <- dat[order(dat$Value_2010,decreasing=TRUE),]
tot <- sum(dat$Value_2010)
cum <- 0
names(dat) <- c("Metro1","Metro2","Value","PairName")
whatShare <- function(e){
cum <<- e + cum
return(cum/tot)
}
shares <- sapply(dat$Value,whatShare)
keepers <- dat[shares<0.9,]
others <- dat[shares>=0.9,]
otherTotal <- sum(others$Value)
print(paste("Rolling up",nrow(others),"observations into an 'other' category, accounting for",otherTotal,"dollars, or",round(otherTotal/tot,4),"of all value."))
keepers <- aggregate(keepers["Value"],by=keepers["Metro2"],sum)
#keepers <- keepers[order(keepers$Value,decreasing=TRUE),]
keepers <- rbind(data.frame(Metro2=e,Value=0),keepers)
row_num_check <- nrow(keepers)
keepers <- merge(keepers,lookup2[c("Geo_ID","Geo_Description","Viz_Tick","CensusDiv")],by.x="Metro2",by.y="Geo_ID")
if(row_num_check!=nrow(keepers)){stop("Bad lookup of geo names")}
keepers <- keepers[order(keepers$Viz_Tick),]
final_index <- which(as.character(e)==as.character(keepers$Metro2))
if(length(final_index)!=1){stop("Error locating index of passed geography.")}
row <- c(keepers$Value,otherTotal)
nfill <- length(row) #doesn't account for 1 others observation
filler <- matrix(rep(0,(nfill^2)),nrow=nfill)
filler[final_index,] <- row
filler[,final_index] <- row
#places <- lookup[match(keepers$Metro2,lookup$Geo_ID),c("Geo_ID","Geo_Description")]
#print(sum(as.character(places$Geo_ID)==as.character(keepers$Metro2))==nrow(keepers))
places <- keepers[c("Geo_Description","CensusDiv")]
places <- rbind(places,data.frame(Geo_Description="Aggregate of Other Flows",CensusDiv="OTHER"))
#return(list(dat=filler_2,ordering=places))
return(list(data=filler,places=places))
}
library(jsonlite)
test <- getFlow(35620)
writeLines(toJSON(test),paste("/home/alec/Dropbox/Projects/Brookings/DataViz/FreightFlows/metflows/","NYC",".json",sep=""))
####RUN THE FULL DATASET
sums <- rbind(sumDomestic[1:75,],sumForeign[1:25,]) #top 50 domestic, top 15 foreign
#sum(sumDomestic[1:100,"Value_2010"])/sum(sums$Value_2010)
sums <- sums[order(sums$Viz_Tick),]
GC4Matrix <- as.character(sumForeign[1:25,"Geo_ID"])
#use dataOrder to create a function that creates a 449x449 matrix showing balance (not directed) relationships
GlobalCodeStacker <- data.frame(Trader_Code=GC4Matrix,Value_2010=0,pair="global-global")
makeRow <- function(e){
e <- as.character(e) #convert to character
#extract data for this code
if(e %in% as.character(lookupD$Geo_ID)){
dat <- flows[as.character(flows$Metro_Code)==e,c("Metro_Code","Trader_Code","Value_2010","pair")]
dat <- rbind(dat,data.frame(Metro_Code=e,Trader_Code=e,Value_2010=0,pair=paste(e,e,sep="-")))
names(dat) <- c("Metro1","Metro2","Value","PairName")
} else if(e %in% as.character(lookupG$Geo_ID)){
dat <- flows[as.character(flows$Trader_Code)==e,c("Trader_Code","Metro_Code","Value_2010","pair")]
GlobalCodeStacker$Metro_Code <- e #since this actually reassigns to GlobalCodeStacker, and assignments are done in local scope (<- vs <<-), it does not affect the outer value (i.e. a local copy is made)
dat <- rbind(dat,GlobalCodeStacker)
names(dat) <- c("Metro1","Metro2","Value","PairName")
} else{
print(paste("No data found for:",e))
dat <- NULL
}
#need to limit the number of rows to match what is in the 150 chosen places
dat <- dat[as.character(dat$Metro2) %in% as.character(sums$Geo_ID),]
#reorder dat so it matches the order of Viz_Tick
if(!is.null(dat)){
dat$order <- factor(dat$Metro2,levels=as.character(lookup2$Geo_ID)) #relies on lookup2 to be sorted
dat <- dat[order(dat$order),]
row <- matrix(dat$Value,nrow=1,dimnames=list(Metro1=e,Metro2=as.character(dat$order)))
}
#need to reorder and create a matrix with a single row with dimnames of (e,dataOrder$order) obviously data must match
return(row)
}
test2 <- lapply(sums$Geo_ID,makeRow) #relies on sums being sorted
bigMatrix <- do.call(rbind,test2)
labels <- sums[c("Geo_Description","CensusDiv")]
library(jsonlite)
json<-toJSON(list(data=bigMatrix,places=labels))
writeLines(json,"/home/alec/Dropbox/Projects/Brookings/DataViz/FreightFlows/metflows/bigMatrix.json")
sumDomestic <- aggregate(flows[c("Value_2010","Outflow","Inflow")],flows["Metro_Code"],sum)
sumDomestic <- merge(lookupD,sumDomestic,by.x="Geo_ID",by.y="Metro_Code")
sumDomestic <- sumDomestic[order(sumDomestic$Value_2010,decreasing=TRUE),]
#Largest Foreign
sumForeign <- aggregate(flows[c("Value_2010","Outflow","Inflow")],flows["Trader_Code"],sum)
sumForeign <- merge(lookupG,sumForeign,by.x="Geo_ID",by.y="Trader_Code")
sumForeign <- sumForeign[order(sumForeign$Value_2010,decreasing=TRUE),]
#Code that, for a place, pulls 90% of traffic
getFlow <- function(geoID){
e <- as.character(geoID) #convert to character
#extract data for this (domestic) code
dat <- flows[as.character(flows$Metro_Code)==e,c("Metro_Code","Trader_Code","Value_2010","pair")]
dat <- dat[order(dat$Value_2010,decreasing=TRUE),]
tot <- sum(dat$Value_2010)
cum <- 0
names(dat) <- c("Metro1","Metro2","Value","PairName")
whatShare <- function(e){
cum <<- e + cum
return(cum/tot)
}
shares <- sapply(dat$Value,whatShare)
keepers <- dat[shares<0.9,]
others <- dat[shares>=0.9,]
otherTotal <- sum(others$Value)
print(paste("Rolling up",nrow(others),"observations into an 'other' category, accounting for",otherTotal,"dollars, or",round(otherTotal/tot,4),"of all value."))
keepers <- aggregate(keepers["Value"],by=keepers["Metro2"],sum)
#keepers <- keepers[order(keepers$Value,decreasing=TRUE),]
keepers <- rbind(data.frame(Metro2=e,Value=0),keepers)
row_num_check <- nrow(keepers)
keepers <- merge(keepers,lookup2[c("Geo_ID","Geo_Description","Viz_Tick","CensusDiv")],by.x="Metro2",by.y="Geo_ID")
if(row_num_check!=nrow(keepers)){stop("Bad lookup of geo names")}
keepers <- keepers[order(keepers$Viz_Tick),]
final_index <- which(as.character(e)==as.character(keepers$Metro2))
if(length(final_index)!=1){stop("Error locating index of passed geography.")}
row <- c(keepers$Value,otherTotal)
nfill <- length(row) #doesn't account for 1 others observation
filler <- matrix(rep(0,(nfill^2)),nrow=nfill)
filler[final_index,] <- row
filler[,final_index] <- row
#places <- lookup[match(keepers$Metro2,lookup$Geo_ID),c("Geo_ID","Geo_Description")]
#print(sum(as.character(places$Geo_ID)==as.character(keepers$Metro2))==nrow(keepers))
places <- keepers[c("Geo_Description","CensusDiv")]
places <- rbind(places,data.frame(Geo_Description="Aggregate of Other Flows",CensusDiv="OTHER"))
#return(list(dat=filler_2,ordering=places))
return(list(data=filler,places=places))
}
library(jsonlite)
test <- getFlow(35620)
writeLines(toJSON(test),paste("/home/alec/Dropbox/Projects/Brookings/DataViz/FreightFlows/metflows/","NYC",".json",sep=""))
#Code that, for a place, pulls 90% of traffic
getFlow <- function(geoID){
e <- as.character(geoID) #convert to character
#extract data for this (domestic) code
dat <- flows[as.character(flows$Metro_Code)==e,c("Metro_Code","Trader_Code","Value_2010","pair")]
dat <- dat[order(dat$Value_2010,decreasing=TRUE),]
tot <- sum(dat$Value_2010)
cum <- 0
names(dat) <- c("Metro1","Metro2","Value","PairName")
whatShare <- function(e){
cum <<- e + cum
return(cum/tot)
}
shares <- sapply(dat$Value,whatShare)
keepers <- dat[shares<0.85,]
others <- dat[shares>=0.85,]
otherTotal <- sum(others$Value)
print(paste("Rolling up",nrow(others),"observations into an 'other' category, accounting for",otherTotal,"dollars, or",round(otherTotal/tot,4),"of all value."))
keepers <- aggregate(keepers["Value"],by=keepers["Metro2"],sum)
#keepers <- keepers[order(keepers$Value,decreasing=TRUE),]
keepers <- rbind(data.frame(Metro2=e,Value=0),keepers)
row_num_check <- nrow(keepers)
keepers <- merge(keepers,lookup2[c("Geo_ID","Geo_Description","Viz_Tick","CensusDiv")],by.x="Metro2",by.y="Geo_ID")
if(row_num_check!=nrow(keepers)){stop("Bad lookup of geo names")}
keepers <- keepers[order(keepers$Viz_Tick),]
final_index <- which(as.character(e)==as.character(keepers$Metro2))
if(length(final_index)!=1){stop("Error locating index of passed geography.")}
row <- c(keepers$Value,otherTotal)
nfill <- length(row) #doesn't account for 1 others observation
filler <- matrix(rep(0,(nfill^2)),nrow=nfill)
filler[final_index,] <- row
filler[,final_index] <- row
#places <- lookup[match(keepers$Metro2,lookup$Geo_ID),c("Geo_ID","Geo_Description")]
#print(sum(as.character(places$Geo_ID)==as.character(keepers$Metro2))==nrow(keepers))
places <- keepers[c("Geo_Description","CensusDiv")]
places <- rbind(places,data.frame(Geo_Description="Aggregate of Other Flows",CensusDiv="OTHER"))
#return(list(dat=filler_2,ordering=places))
return(list(data=filler,places=places))
}
library(jsonlite)
test <- getFlow(35620)
writeLines(toJSON(test),paste("/home/alec/Dropbox/Projects/Brookings/DataViz/FreightFlows/metflows/","NYC",".json",sep=""))
q()
