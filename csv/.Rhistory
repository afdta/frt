dcast(a,~age,value.var="pop")
dcast(a,~age,value.var="pop")
str(a)
dcast(a,1~age,value.var="pop")
dcast(a,.~age,value.var="pop")
str(dcast(a,.~age,value.var="pop"))
a
matrix(1:5,nrow=1,dimnames=list(null,c("a","b","c","d","e")))
matrix(1:5,nrow=1,dimnames=list(NULL,c("a","b","c","d","e")))
library(reshape2)
cSplit <- split(Autauga,Autauga$stcofips)
cSplit2 <- lapply(cSplit,function(e){
e <- e[,c("Group3","Age2","Pop")]
eSplit <- split(e,as.character(e$Group3))
ret <- lapply(eSplit,function(e){
return(matrix(eSplit$Pop,nrow=1,dimnames=list(NULL,eSplit$Age2)))
})
return(ret)
})
matrix(1:5,nrow=1,dimnames=list(NULL,c("a","b","c","d","e")))
library(reshape2)
cSplit <- split(Autauga,Autauga$stcofips)
cSplit2 <- lapply(cSplit,function(e){
e <- e[,c("Group3","Age2","Pop")]
eSplit <- split(e,as.character(e$Group3))
ret <- lapply(eSplit,function(e){
return(matrix(e$Pop,nrow=1,dimnames=list(NULL,e$Age2)))
})
return(ret)
})
library(jsonlite)
json <- toJSON(cSplit2,na="null",factor="integer")
writeLines(json,"/home/alec/Dropbox/Projects/Brookings/DataViz/DiversityExplosion/data/json/countydat.json")
cSplit2
json <- toJSON(cSplit2,na="null")
writeLines(json,"/home/alec/Dropbox/Projects/Brookings/DataViz/DiversityExplosion/data/json/countydat.json")
cSplit2 <- lapply(cSplit,function(e){
e <- e[,c("Group3","Age2","Pop")]
eSplit <- split(e,as.character(e$Group3))
ret <- lapply(eSplit,function(e){
return(as.data.frame(matrix(e$Pop,nrow=1,dimnames=list(NULL,e$Age2))))
})
return(ret)
})
library(jsonlite)
json <- toJSON(cSplit2,na="null")
writeLines(json,"/home/alec/Dropbox/Projects/Brookings/DataViz/DiversityExplosion/data/json/countydat.json")
cSplit2
cSplit <- split(Autauga,Autauga$stcofips)
cSplit2 <- lapply(cSplit,function(e){
e <- e[,c("Group3","Age2","Pop")]
eSplit <- split(e,as.character(e$Group3))
ret <- lapply(eSplit,function(e){
v <- e$Pop
names(v) <- e$Age2
return(v)
})
return(ret)
})
library(jsonlite)
json <- toJSON(cSplit2,na="null")
writeLines(json,"/home/alec/Dropbox/Projects/Brookings/DataViz/DiversityExplosion/data/json/countydat.json")
library(reshape2)
cSplit <- split(Autauga,Autauga$stcofips)
cSplit2 <- lapply(cSplit,function(e){
e <- e[,c("Group3","Age2","Pop")]
eSplit <- split(e,as.character(e$Group3))
ret <- lapply(eSplit,function(e){
v <- as.vector(e$Pop, mode="list")
names(v) <- e$Age2
return(v)
})
return(ret)
})
library(jsonlite)
json <- toJSON(cSplit2,na="null")
writeLines(json,"/home/alec/Dropbox/Projects/Brookings/DataViz/DiversityExplosion/data/json/countydat.json")
keep <- c("TOT_POP", "TOT", "NH", "NHWA", "NHBA", "NHIA", "NHAA", "NHNA", "NHTOM", "H2")
sums2 <- sums[sums$Group3 %in% keep,]
sums2 <- sums2[order(sums2$STATE,sums2$COUNTY,sums2$Group3,sums2$Age2),]
cSplit <- split(sums2,sums2$stcofips)
cSplit2 <- lapply(cSplit,function(e){
e <- e[,c("Group3","Age2","Pop")]
eSplit <- split(e,as.character(e$Group3))
ret <- lapply(eSplit,function(e){
v <- as.vector(e$Pop, mode="list")
names(v) <- e$Age2
return(v)
})
return(ret)
})
sums$stcofips <- ifelse(sums$STATE<10,paste("0",sums$STATE,sep=""),sums$STATE)
sums$stcofips <- paste("C",sums$stcofips, ifelse(sums$COUNTY<10,paste("00",sums$COUNTY,sep=""),ifelse(sums$COUNTY<100,paste("0",sums$COUNTY,sep=""),as.character(sums$COUNTY))),sep="")
keep <- c("TOT_POP", "TOT", "NH", "NHWA", "NHBA", "NHIA", "NHAA", "NHNA", "NHTOM", "H2")
sums2 <- sums[sums$Group3 %in% keep,]
sums2 <- sums2[order(sums2$STATE,sums2$COUNTY,sums2$Group3,sums2$Age2),]
cSplit <- split(sums2,sums2$stcofips)
cSplit2 <- lapply(cSplit,function(e){
e <- e[,c("Group3","Age2","Pop")]
eSplit <- split(e,as.character(e$Group3))
ret <- lapply(eSplit,function(e){
v <- as.vector(e$Pop, mode="list")
names(v) <- e$Age2
return(v)
})
return(ret)
})
json <- toJSON(cSplit2,na="null",factor="integer")
writeLines(json,"/home/alec/Dropbox/Projects/Brookings/DataViz/DiversityExplosion/data/json/countydat.json")
levels(as.factor(sums2$stcofips))
levels(as.factor(sums2$Group3))
levels(as.factor(as.character(sums2$Group3)))
dput(levels(as.factor(as.character(sums2$Group3))))
dput(levels(as.factor(as.character(sums2$Age2))))
dput(levels(as.factor(sums2$stcofips)))
q()
load("/home/alec/Dropbox/Projects/Brookings/DataViz/DiversityExplosion/data/json/RDat.RData")
aggregate(sums["Pop"],by=sums[c("Group2","Age2")],max)
MAX <- aggregate(sums["Pop"],by=sums[c("Group2","Age2")],max)
View(MAX)
MAX[MAX$Group2=="TOT",]
ALLMAX<-MAX[MAX$Group2=="TOT",]
ALLMAX
sum(ALLMAX[1:7,"Pop"])
SUM <- aggregate(sums["Pop"],by=sums[c("Group2","Age2")],sum)
ALLSUM<-SUM[SUM$Group2=="TOT",]
ALLSUM
ALLMAX
counties <- unique(sums[c("stcofips","CTYNAME")])
counties
counties <- unique(sums[c("stcofips","CTYNAME","STNAME")])
counties
countysplit <- split(counties[c("CTYNAME","STNAME")],counties$stcofips)
countyJSON <- toJSON(countysplit)
library(jsonlite)
countyJSON <- toJSON(countysplit)
countyJSON
countysplit2 <- lapply(countysplit, function(e){return(paste(e[1,"CTYNAME"],e[1,"STNAME"],sep=", "))})
countysplit2
countyJSON <- toJSON(countysplit2)
countyJSON
countyJSON <- toJSON(countysplit2,auto_unbox=TRUE)
countyJSON
writeLines(countyJSON,"/home/alec/Dropbox/Projects/Brookings/DataViz/DiversityExplosion/data/json/countyNames.json")
sums[sums$stcofips=="C48301",]
q()
load("/home/alec/Dropbox/Projects/Brookings/DataViz/DiversityExplosion/data/json/RDat.RData")
c <- levels(factor(sums$stcofips))
library(rgdal)
countyMap <- readOGR("/home/alec/Dropbox/Projects/Brookings/DataViz/QuickMap/build",layer="gz_2010_us_050_00_20m.dbf")
countyMap <- readOGR("/home/alec/Dropbox/Projects/Brookings/DataViz/QuickMap/build/",layer="gz_2010_us_050_00_20m.dbf")
countyMap <- readOGR(dsn="/home/alec/Dropbox/Projects/Brookings/DataViz/QuickMap/build/",layer="gz_2010_us_050_00_20m.dbf")
countyMap <- readOGR(dsn="/home/alec/Dropbox/Projects/Brookings/DataViz/QuickMap/build/",layer="gz_2010_us_050_00_20m")
plot(countyMap)
head(countyMap@data)
states<-levels(factor(countyMap@data))
states<-levels(factor(countyMap@data$STATE))
states
countyMap2 <- countyMap[countyMap@data$STATE!="72",]
nrow(countyMap2@data)
source("/home/alec/Dropbox/Projects/Brookings/DataViz/FreightFlows/R/1. Import and Process.R")
library(ggplot2)
flowList <- split(flows,flows$Group_ID)
#big function to be applied to each member of flowList
squareMatrix <- function(df){
#Commodity code
commCode <- df[1,"Group_ID"]
print(paste("Running data for commodity group",commCode))
#Largest Domestic
sumDomestic <- aggregate(df["Value_2010"],df["Metro_Code"],sum)
sumDomestic <- merge(lookupD,sumDomestic,by.x="Geo_ID",by.y="Metro_Code")
sumDomestic <- sumDomestic[order(sumDomestic$Value_2010,decreasing=TRUE),]
#Largest Foreign
sumForeign <- aggregate(df["Value_2010"],df["Trader_Code"],sum)
sumForeign <- merge(lookupG,sumForeign,by.x="Geo_ID",by.y="Trader_Code")
sumForeign <- sumForeign[order(sumForeign$Value_2010,decreasing=TRUE),]
numDom <- nrow(sumDomestic)
numFor <- nrow(sumForeign)
if(numDom > 75){numDom <- 75}
if(numFor > 25){numFor <- 25}
print(paste("Pulling the top",numDom,"domestic flows and the top",numFor,"foreign flows"))
if(numDom > 0 && numFor > 0){
sums <- rbind(sumDomestic[1:numDom,],sumForeign[1:numFor,]) #top 75 domestic, top 25 foreign
} else if(numDom > 0){
sums <- sumDomestic[1:numDom,]
} else if(numFor > 0){
sums <- sumForeign[1:numFor,]
}
sums <- sums[order(sums$Viz_Tick),]
GC4Matrix <- as.character(sumForeign[1:25,"Geo_ID"])
GlobalCodeStacker <- data.frame(Trader_Code=GC4Matrix,Value_2010=0) #used as a spacer below to round out square matrix
makeRow <- function(e){
e <- as.character(e) #convert to character
#extract data for this code
if(e %in% as.character(lookupD$Geo_ID)){
dat <- df[as.character(df$Metro_Code)==e,c("Metro_Code","Trader_Code","Value_2010")]
dat <- rbind(dat,data.frame(Metro_Code=e,Trader_Code=e,Value_2010=0)) #to complete square matrix
names(dat) <- c("Metro1","Metro2","Value")
} else if(e %in% as.character(lookupG$Geo_ID)){
dat <- df[as.character(df$Trader_Code)==e,c("Trader_Code","Metro_Code","Value_2010")]
GlobalCodeStacker$Metro_Code <- e #since this actually reassigns to GlobalCodeStacker, and assignments are done in local scope (<- vs <<-), it does not affect the outer value (i.e. a local copy is made)
dat <- rbind(dat,GlobalCodeStacker)
names(dat) <- c("Metro1","Metro2","Value")
} else{
print(paste("No data found for:",e))
dat <- data.frame(Metro1=character(0),Metro2=character(0),Value=numeric(0));
}
#need to limit the number of connections to the chosen universe of top 75/25 (matrix must be square)
dat <- dat[as.character(dat$Metro2) %in% as.character(sums$Geo_ID),]
if(nrow(dat) < nrow(sums)){
#if there are missing connections listed, pad the data with 0s
nodata <- sums[!(sums$Geo_ID %in% dat$Metro2),"Geo_ID"]
nodata <- data.frame(Metro2=nodata)
nodata$Metro1 <- e
nodata$Value <- 0
dat <- rbind(dat,nodata)
}
dat[dat$Value < 0.1,"Value"] <- 0 #prevents errors in D3 rendering
#reorder dat so it matches the order of Viz_Tick
if(!is.null(dat)){
dat$order <- factor(dat$Metro2,levels=as.character(sums$Geo_ID)) #row will be sorted in same order as sums
dat <- dat[order(dat$order),]
row <- matrix(dat$Value,nrow=1,dimnames=list(Metro1=e,Metro2=as.character(dat$Metro2)))
}
return(row)
} #end makeRow
getMax <- function(e){
e <- as.character(e) #convert to character
#extract data for this code
if(e %in% as.character(lookupD$Geo_ID)){
dat <- df[as.character(df$Metro_Code)==e,"Value_2010"]
} else if(e %in% as.character(lookupG$Geo_ID)){
dat <- df[as.character(df$Trader_Code)==e,"Value_2010"]
} else{
print(paste("No data found for:",e))
dat <- NULL
}
return(max(dat))
}
allRows <- lapply(sums$Geo_ID,makeRow) #relies on sums being sorted
bigMatrix <- do.call(rbind,allRows)
labels <- sums[c("fullname","CensusDiv","Geo_ID")]
maxVals <- sapply(sums$Geo_ID,getMax)
return(list(data=bigMatrix,places=labels,max=maxVals,commodity=commCode))
}
options(scipen=999)
squareMatrix <- function(df){
#Commodity code
commCode <- df[1,"Group_ID"]
print(paste("Running data for commodity group",commCode))
#Largest Domestic
sumDomestic <- aggregate(df["Value_2010"],df["Metro_Code"],sum)
sumDomestic <- merge(lookupD,sumDomestic,by.x="Geo_ID",by.y="Metro_Code")
sumDomestic <- sumDomestic[order(sumDomestic$Value_2010,decreasing=TRUE),]
#Largest Foreign
sumForeign <- aggregate(df["Value_2010"],df["Trader_Code"],sum)
sumForeign <- merge(lookupG,sumForeign,by.x="Geo_ID",by.y="Trader_Code")
sumForeign <- sumForeign[order(sumForeign$Value_2010,decreasing=TRUE),]
numDom <- nrow(sumDomestic)
numFor <- nrow(sumForeign)
if(numDom > 75){numDom <- 75}
if(numFor > 25){numFor <- 25}
print(paste("Pulling the top",numDom,"domestic flows and the top",numFor,"foreign flows"))
if(numDom > 0 && numFor > 0){
sums <- rbind(sumDomestic[1:numDom,],sumForeign[1:numFor,]) #top 75 domestic, top 25 foreign
} else if(numDom > 0){
sums <- sumDomestic[1:numDom,]
} else if(numFor > 0){
sums <- sumForeign[1:numFor,]
}
sums <- sums[order(sums$Viz_Tick),]
GC4Matrix <- as.character(sumForeign[1:25,"Geo_ID"])
GlobalCodeStacker <- data.frame(Trader_Code=GC4Matrix,Value_2010=0) #used as a spacer below to round out square matrix
makeRow <- function(e){
e <- as.character(e) #convert to character
#extract data for this code
if(e %in% as.character(lookupD$Geo_ID)){
dat <- df[as.character(df$Metro_Code)==e,c("Metro_Code","Trader_Code","Value_2010")]
dat <- rbind(dat,data.frame(Metro_Code=e,Trader_Code=e,Value_2010=0)) #to complete square matrix
names(dat) <- c("Metro1","Metro2","Value")
} else if(e %in% as.character(lookupG$Geo_ID)){
dat <- df[as.character(df$Trader_Code)==e,c("Trader_Code","Metro_Code","Value_2010")]
GlobalCodeStacker$Metro_Code <- e #since this actually reassigns to GlobalCodeStacker, and assignments are done in local scope (<- vs <<-), it does not affect the outer value (i.e. a local copy is made)
dat <- rbind(dat,GlobalCodeStacker)
names(dat) <- c("Metro1","Metro2","Value")
} else{
print(paste("No data found for:",e))
dat <- data.frame(Metro1=character(0),Metro2=character(0),Value=numeric(0));
}
#need to limit the number of connections to the chosen universe of top 75/25 (matrix must be square)
dat <- dat[as.character(dat$Metro2) %in% as.character(sums$Geo_ID),]
if(nrow(dat) < nrow(sums)){
#if there are missing connections listed, pad the data with 0s
nodata <- sums[!(sums$Geo_ID %in% dat$Metro2),"Geo_ID"]
nodata <- data.frame(Metro2=nodata)
nodata$Metro1 <- e
nodata$Value <- 0
dat <- rbind(dat,nodata)
}
dat[dat$Value < 0.5,"Value"] <- 0 #prevents errors in D3 rendering
#reorder dat so it matches the order of Viz_Tick
if(!is.null(dat)){
dat$order <- factor(dat$Metro2,levels=as.character(sums$Geo_ID)) #row will be sorted in same order as sums
dat <- dat[order(dat$order),]
row <- matrix(dat$Value,nrow=1,dimnames=list(Metro1=e,Metro2=as.character(dat$Metro2)))
}
return(row)
} #end makeRow
getMax <- function(e){
e <- as.character(e) #convert to character
#extract data for this code
if(e %in% as.character(lookupD$Geo_ID)){
dat <- df[as.character(df$Metro_Code)==e,"Value_2010"]
} else if(e %in% as.character(lookupG$Geo_ID)){
dat <- df[as.character(df$Trader_Code)==e,"Value_2010"]
} else{
print(paste("No data found for:",e))
dat <- NULL
}
return(max(dat))
}
allRows <- lapply(sums$Geo_ID,makeRow) #relies on sums being sorted
bigMatrix <- do.call(rbind,allRows)
labels <- sums[c("fullname","CensusDiv","Geo_ID")]
maxVals <- sapply(sums$Geo_ID,getMax)
return(list(data=bigMatrix,places=labels,max=maxVals,commodity=commCode))
}
options(scipen=999)
bigBigMatrix <- lapply(flowList[1],squareMatrix)
for(i in bigBigMatrix){
writeLines(toJSON(i),paste("/home/alec/Dropbox/Projects/Brookings/DataViz/FreightFlows/json/chord_data/bigMatrix_",i$commodity,".json",sep=""))
}
library(jsonlite)
for(i in bigBigMatrix){
writeLines(toJSON(i),paste("/home/alec/Dropbox/Projects/Brookings/DataViz/FreightFlows/json/chord_data/bigMatrix_",i$commodity,".json",sep=""))
}
squareMatrix <- function(df){
#Commodity code
commCode <- df[1,"Group_ID"]
print(paste("Running data for commodity group",commCode))
#Largest Domestic
sumDomestic <- aggregate(df["Value_2010"],df["Metro_Code"],sum)
sumDomestic <- merge(lookupD,sumDomestic,by.x="Geo_ID",by.y="Metro_Code")
sumDomestic <- sumDomestic[order(sumDomestic$Value_2010,decreasing=TRUE),]
#Largest Foreign
sumForeign <- aggregate(df["Value_2010"],df["Trader_Code"],sum)
sumForeign <- merge(lookupG,sumForeign,by.x="Geo_ID",by.y="Trader_Code")
sumForeign <- sumForeign[order(sumForeign$Value_2010,decreasing=TRUE),]
numDom <- nrow(sumDomestic)
numFor <- nrow(sumForeign)
if(numDom > 75){numDom <- 75}
if(numFor > 25){numFor <- 25}
print(paste("Pulling the top",numDom,"domestic flows and the top",numFor,"foreign flows"))
if(numDom > 0 && numFor > 0){
sums <- rbind(sumDomestic[1:numDom,],sumForeign[1:numFor,]) #top 75 domestic, top 25 foreign
} else if(numDom > 0){
sums <- sumDomestic[1:numDom,]
} else if(numFor > 0){
sums <- sumForeign[1:numFor,]
}
sums <- sums[order(sums$Viz_Tick),]
GC4Matrix <- as.character(sumForeign[1:25,"Geo_ID"])
GlobalCodeStacker <- data.frame(Trader_Code=GC4Matrix,Value_2010=0) #used as a spacer below to round out square matrix
makeRow <- function(e){
e <- as.character(e) #convert to character
#extract data for this code
if(e %in% as.character(lookupD$Geo_ID)){
dat <- df[as.character(df$Metro_Code)==e,c("Metro_Code","Trader_Code","Value_2010")]
dat <- rbind(dat,data.frame(Metro_Code=e,Trader_Code=e,Value_2010=0)) #to complete square matrix
names(dat) <- c("Metro1","Metro2","Value")
} else if(e %in% as.character(lookupG$Geo_ID)){
dat <- df[as.character(df$Trader_Code)==e,c("Trader_Code","Metro_Code","Value_2010")]
GlobalCodeStacker$Metro_Code <- e #since this actually reassigns to GlobalCodeStacker, and assignments are done in local scope (<- vs <<-), it does not affect the outer value (i.e. a local copy is made)
dat <- rbind(dat,GlobalCodeStacker)
names(dat) <- c("Metro1","Metro2","Value")
} else{
print(paste("No data found for:",e))
dat <- data.frame(Metro1=character(0),Metro2=character(0),Value=numeric(0));
}
#need to limit the number of connections to the chosen universe of top 75/25 (matrix must be square)
dat <- dat[as.character(dat$Metro2) %in% as.character(sums$Geo_ID),]
if(nrow(dat) < nrow(sums)){
#if there are missing connections listed, pad the data with 0s
nodata <- sums[!(sums$Geo_ID %in% dat$Metro2),"Geo_ID"]
nodata <- data.frame(Metro2=nodata)
nodata$Metro1 <- e
nodata$Value <- 0
dat <- rbind(dat,nodata)
}
dat[dat$Value < 1,"Value"] <- 0 #prevents errors in D3 rendering
#reorder dat so it matches the order of Viz_Tick
if(!is.null(dat)){
dat$order <- factor(dat$Metro2,levels=as.character(sums$Geo_ID)) #row will be sorted in same order as sums
dat <- dat[order(dat$order),]
row <- matrix(dat$Value,nrow=1,dimnames=list(Metro1=e,Metro2=as.character(dat$Metro2)))
}
return(row)
} #end makeRow
getMax <- function(e){
e <- as.character(e) #convert to character
#extract data for this code
if(e %in% as.character(lookupD$Geo_ID)){
dat <- df[as.character(df$Metro_Code)==e,"Value_2010"]
} else if(e %in% as.character(lookupG$Geo_ID)){
dat <- df[as.character(df$Trader_Code)==e,"Value_2010"]
} else{
print(paste("No data found for:",e))
dat <- NULL
}
return(max(dat))
}
allRows <- lapply(sums$Geo_ID,makeRow) #relies on sums being sorted
bigMatrix <- do.call(rbind,allRows)
labels <- sums[c("fullname","CensusDiv","Geo_ID")]
maxVals <- sapply(sums$Geo_ID,getMax)
return(list(data=bigMatrix,places=labels,max=maxVals,commodity=commCode))
}
options(scipen=999)
bigBigMatrix <- lapply(flowList[1],squareMatrix)
library(jsonlite)
for(i in bigBigMatrix){
writeLines(toJSON(i),paste("/home/alec/Dropbox/Projects/Brookings/DataViz/FreightFlows/json/chord_data/bigMatrix_",i$commodity,".json",sep=""))
}
#big function to be applied to each member of flowList
squareMatrix <- function(df){
#Commodity code
commCode <- df[1,"Group_ID"]
print(paste("Running data for commodity group",commCode))
#Largest Domestic
sumDomestic <- aggregate(df["Value_2010"],df["Metro_Code"],sum)
sumDomestic <- merge(lookupD,sumDomestic,by.x="Geo_ID",by.y="Metro_Code")
sumDomestic <- sumDomestic[order(sumDomestic$Value_2010,decreasing=TRUE),]
#Largest Foreign
sumForeign <- aggregate(df["Value_2010"],df["Trader_Code"],sum)
sumForeign <- merge(lookupG,sumForeign,by.x="Geo_ID",by.y="Trader_Code")
sumForeign <- sumForeign[order(sumForeign$Value_2010,decreasing=TRUE),]
numDom <- nrow(sumDomestic)
numFor <- nrow(sumForeign)
if(numDom > 75){numDom <- 75}
if(numFor > 25){numFor <- 25}
print(paste("Pulling the top",numDom,"domestic flows and the top",numFor,"foreign flows"))
if(numDom > 0 && numFor > 0){
sums <- rbind(sumDomestic[1:numDom,],sumForeign[1:numFor,]) #top 75 domestic, top 25 foreign
} else if(numDom > 0){
sums <- sumDomestic[1:numDom,]
} else if(numFor > 0){
sums <- sumForeign[1:numFor,]
}
sums <- sums[order(sums$Viz_Tick),]
GC4Matrix <- as.character(sumForeign[1:25,"Geo_ID"])
GlobalCodeStacker <- data.frame(Trader_Code=GC4Matrix,Value_2010=0) #used as a spacer below to round out square matrix
makeRow <- function(e){
e <- as.character(e) #convert to character
#extract data for this code
if(e %in% as.character(lookupD$Geo_ID)){
dat <- df[as.character(df$Metro_Code)==e,c("Metro_Code","Trader_Code","Value_2010")]
dat <- rbind(dat,data.frame(Metro_Code=e,Trader_Code=e,Value_2010=0)) #to complete square matrix
names(dat) <- c("Metro1","Metro2","Value")
} else if(e %in% as.character(lookupG$Geo_ID)){
dat <- df[as.character(df$Trader_Code)==e,c("Trader_Code","Metro_Code","Value_2010")]
GlobalCodeStacker$Metro_Code <- e #since this actually reassigns to GlobalCodeStacker, and assignments are done in local scope (<- vs <<-), it does not affect the outer value (i.e. a local copy is made)
dat <- rbind(dat,GlobalCodeStacker)
names(dat) <- c("Metro1","Metro2","Value")
} else{
print(paste("No data found for:",e))
dat <- data.frame(Metro1=character(0),Metro2=character(0),Value=numeric(0));
}
#need to limit the number of connections to the chosen universe of top 75/25 (matrix must be square)
dat <- dat[as.character(dat$Metro2) %in% as.character(sums$Geo_ID),]
if(nrow(dat) < nrow(sums)){
#if there are missing connections listed, pad the data with 0s
nodata <- sums[!(sums$Geo_ID %in% dat$Metro2),"Geo_ID"]
nodata <- data.frame(Metro2=nodata)
nodata$Metro1 <- e
nodata$Value <- 0
dat <- rbind(dat,nodata)
}
dat[dat$Value < 0.1,"Value"] <- 0 #prevents errors in D3 rendering
#reorder dat so it matches the order of Viz_Tick
if(!is.null(dat)){
dat$order <- factor(dat$Metro2,levels=as.character(sums$Geo_ID)) #row will be sorted in same order as sums
dat <- dat[order(dat$order),]
row <- matrix(dat$Value,nrow=1,dimnames=list(Metro1=e,Metro2=as.character(dat$Metro2)))
}
return(row)
} #end makeRow
getMax <- function(e){
e <- as.character(e) #convert to character
#extract data for this code
if(e %in% as.character(lookupD$Geo_ID)){
dat <- df[as.character(df$Metro_Code)==e,"Value_2010"]
} else if(e %in% as.character(lookupG$Geo_ID)){
dat <- df[as.character(df$Trader_Code)==e,"Value_2010"]
} else{
print(paste("No data found for:",e))
dat <- NULL
}
return(max(dat))
}
allRows <- lapply(sums$Geo_ID,makeRow) #relies on sums being sorted
bigMatrix <- do.call(rbind,allRows)
labels <- sums[c("fullname","CensusDiv","Geo_ID")]
maxVals <- sapply(sums$Geo_ID,getMax)
return(list(data=bigMatrix,places=labels,max=maxVals,commodity=commCode))
}
options(scipen=999)
bigBigMatrix <- lapply(flowList[1],squareMatrix)
library(jsonlite)
for(i in bigBigMatrix){
writeLines(toJSON(i),paste("/home/alec/Dropbox/Projects/Brookings/DataViz/FreightFlows/json/chord_data/bigMatrix_",i$commodity,".json",sep=""))
}
q()
